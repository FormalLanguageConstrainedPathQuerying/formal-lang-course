{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kznts9v-1lya/formal-lang-course/blob/task5-rpq-research/researches/rpq_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4X_1vHSZ5cA"
   },
   "source": [
    "# Автор [kznts9v_1lya](https://github.com/kznts9v-1lya)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yk2eMvtFpowo"
   },
   "source": [
    "---\n",
    "\n",
    "# Экспериментальное исследование производительности CPU и GPU версий алгоритма Regular Path Quering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC1AlmimpjT8"
   },
   "source": [
    "## Введение\n",
    "\n",
    "Имеется **размеченный граф** $G$, задающий регулярный язык $L_G$.\n",
    "\n",
    "Имеется **регулярное выражение** $Q$, задающее регулярный язык ограничений $L_Q$.\n",
    "\n",
    "Задача $Regular Path Quering$ решает проблему достижимости между всеми парами вершин с регулярными ограничениями через тензорное произведение. Ограничения представляются в виде пар достижимых вершин графа, представляющего $L_G\\cap L_Q$.\n",
    "\n",
    "$RPQ = \\{(v_i, v_j)|\\exists\\pi:w(v_i\\pi v_j)\\in L, v_i\\in V_S, v_j\\in V_F\\}$, где $L = L_G\\cap L_Q$\n",
    "\n",
    "Известно свойство, что регулярные языки замкнуты относительно пересечения и по ним можно построить конечный автомат, допускающий эти языки. Именно поэтому $RPQ$ строит язык пересечения, задаваемый пересечением двух конечных автоматов $КА_{G}$ и $КА_{Q}$, допускающих $L_G$ и $L_Q$ соответсвенно, --- также конечным автоматом $КА_{I}$.\n",
    "\n",
    "Обратимся к определению, $КА_3 = КА_1\\cap КА_2 = (S^{1}\\times S^{2}, \\Delta^{3}, S^{1}_S\\times S^{2}_S, S^{1}_F\\times S^{2}_F)$, где функция переходов задаётся как\n",
    "$\\Delta^{3}: (v_i, v_j)\\times l_{abel}\\rightarrow (u_i, u_j)$\n",
    "\n",
    "$\n",
    "\\begin{cases}\n",
    "v_i\\in S^{1}\\times l\\rightarrow u_i\\in S^{1}\\in\\Delta^{1} \\\\\n",
    "v_j\\in S^{2}\\times l\\rightarrow u_j\\in S^{2}\\in\\Delta^{2}\n",
    "\\end{cases}$\n",
    "\n",
    "Для нахождения функции переходов $\\Delta^{I}$ используется алгоритм, основанный на тензорном произведении булевых матриц смежности конечных автоматов $КА_{G}$ и $КА_{Q}$, также известном как произведение Кронекера, и последующем построении транизитивного замыкания.\n",
    "\n",
    "В данной работе будет экспериментально исследована скорость работы описанного алгоритма решения проблемы $RPQ$, реализованный в двух вариантах $-$ на $CPU$ и $GPU$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLVGwYe4pibu"
   },
   "source": [
    "---\n",
    "\n",
    "## Постановка цели исследования\n",
    "\n",
    "Для достижения поставленной цели $-$ экспериментального исследования скорости работы описанного алгоритма решения проблемы $RPQ$ $-$ необходимо выполнить следующие подзадачи:\n",
    "\n",
    "- Используя разряженные матрицы [scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html) реализовать алгоритм пересечения двух конечных автоматов через тензорное произведение с использованием $CPU$;\n",
    "- Используя библиотеку [pyCuBool](https://pypi.org/project/pycubool/) реализовать алгоритм пересечения двух конечных автоматов через тензорное произведение с использованием технологии $CUDA$ для $GPU$;\n",
    "- Сформировать датасет, необходимый для проведения экспериментов;\n",
    "- Произвести сравнительный анализ производительности версий алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkVwfu8KfAHo"
   },
   "source": [
    "---\n",
    "\n",
    "## Подготовка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QwsOy8uLoq5y",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Развёртывание репозитория\n",
    "# !git clone https://github.com/kznts9v-1lya/formal-lang-course.git &> /dev/null\n",
    "# !cd formal-lang-course && git checkout task5-rpq-research &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RekSR7GgpBKR",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Установка внешних зависимостей\n",
    "# !pip install -r formal-lang-course/requirements.txt &> /dev/null\n",
    "!pip install pycubool &> /dev/null\n",
    "!pip install pandas &> /dev/null\n",
    "!pip install matplotlib &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1wcQJdNmpK19",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Инициализация директории в окружении\n",
    "# import sys\n",
    "# sys.path.insert(1, 'formal-lang-course')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgbY1sZUfF2z"
   },
   "source": [
    "---\n",
    "\n",
    "## Описание данных исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptGwsEWtpay5"
   },
   "source": [
    "### Графы\n",
    "\n",
    "В качестве $G$ использовуются все графы из [RDF](https://jetbrains-research.github.io/CFPQ_Data/dataset/RDF.html) датасета, за исключением **taxonomy** и **taxonomy_hierarchy** из-за их исключительных размеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "38ck5KGsqlQ8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Названия использующихся графов\n",
    "\n",
    "GRAPH_NAMES = (\n",
    "    \"skos\",\n",
    "    \"generations\",\n",
    "    \"travel\",\n",
    "    \"univ_bench\",\n",
    "    \"atom_primitive\",\n",
    "    \"biomedical_mesure_primitive\",\n",
    "    \"foaf\",\n",
    "    \"people_pets\",\n",
    "    \"funding\",\n",
    "    \"wine\",\n",
    "    \"pizza\",\n",
    "    \"core\",\n",
    "    \"pathways\",\n",
    "    \"enzyme\",\n",
    "    \"go\",\n",
    "    \"go_hierarchy\",\n",
    "    \"eclass_514en\",\n",
    "    \"geospecies\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ROzjp4iuq_fC",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_12537/2073133956.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mgraph_name\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mGRAPH_NAMES\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m   \u001B[0mGRAPHS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_from_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraph_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/project/graph_tools.py\u001B[0m in \u001B[0;36mget_from_dataset\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m    113\u001B[0m     \"\"\"\n\u001B[1;32m    114\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m     \u001B[0mdataset_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcfpq_data\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgraph_from_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mdataset_graph\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/cfpq_data/graphs/readwrite/rdf.py\u001B[0m in \u001B[0;36mgraph_from_dataset\u001B[0;34m(graph_name, verbose)\u001B[0m\n\u001B[1;32m    123\u001B[0m                 \u001B[0mremove\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraph_archive_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_from_rdf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgraph_file_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/cfpq_data/graphs/readwrite/rdf.py\u001B[0m in \u001B[0;36mgraph_from_rdf\u001B[0;34m(source, verbose)\u001B[0m\n\u001B[1;32m    155\u001B[0m     \"\"\"\n\u001B[1;32m    156\u001B[0m     \u001B[0mtmp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRDFGraph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 157\u001B[0;31m     \u001B[0mtmp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"xml\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m     \u001B[0mg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMultiDiGraph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/graph.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(self, source, publicID, format, location, file, data, **args)\u001B[0m\n\u001B[1;32m   1209\u001B[0m         \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mplugin\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mParser\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1210\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1211\u001B[0;31m             \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1212\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mSyntaxError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1213\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mcould_not_guess_format\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/plugins/parsers/rdfxml.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(self, source, sink, **args)\u001B[0m\n\u001B[1;32m    606\u001B[0m         \u001B[0;31m# content_handler.reset()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m         \u001B[0;31m# self._parser.reset()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 608\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msource\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/lib/python3.9/xml/sax/expatreader.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(self, source)\u001B[0m\n\u001B[1;32m    109\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cont_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetDocumentLocator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mExpatLocator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 111\u001B[0;31m             \u001B[0mxmlreader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIncrementalParser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msource\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    112\u001B[0m         \u001B[0;32mexcept\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m             \u001B[0;31m# bpo-30264: Close the source on error to not leak resources:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/xml/sax/xmlreader.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(self, source)\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0mbuffer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_bufsize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfeed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m             \u001B[0mbuffer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_bufsize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/xml/sax/expatreader.py\u001B[0m in \u001B[0;36mfeed\u001B[0;34m(self, data, isFinal)\u001B[0m\n\u001B[1;32m    215\u001B[0m             \u001B[0;31m# document. When feeding chunks, they are not normally final -\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m             \u001B[0;31m# except when invoked from close.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 217\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_parser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mParse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0misFinal\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    218\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mexpat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m             \u001B[0mexc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSAXParseException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexpat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mErrorString\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m../Modules/pyexpat.c\u001B[0m in \u001B[0;36mEndElement\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.9/xml/sax/expatreader.py\u001B[0m in \u001B[0;36mend_element_ns\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    379\u001B[0m             \u001B[0mpair\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpair\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 381\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cont_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mendElementNS\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpair\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    382\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[0;31m# this is not used (call directly to ContentHandler)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/plugins/parsers/rdfxml.py\u001B[0m in \u001B[0;36mendElementNS\u001B[0;34m(self, name, qname)\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    196\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mendElementNS\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 197\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    198\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/plugins/parsers/rdfxml.py\u001B[0m in \u001B[0;36mproperty_element_end\u001B[0;34m(self, name, qname)\u001B[0m\n\u001B[1;32m    505\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRDF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRDF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnil\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    506\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobject\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 507\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredicate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    508\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mid\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    509\u001B[0m                 self.add_reified(\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/graph.py\u001B[0m in \u001B[0;36madd\u001B[0;34m(self, triple)\u001B[0m\n\u001B[1;32m    384\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Predicate %s must be an rdflib term\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    385\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mNode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Object %s must be an rdflib term\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mo\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 386\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__store\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquoted\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    387\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0maddN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquads\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/plugins/stores/memory.py\u001B[0m in \u001B[0;36madd\u001B[0;34m(self, triple, context, quoted)\u001B[0m\n\u001B[1;32m    241\u001B[0m             \u001B[0mo\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mobject_\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    242\u001B[0m             \u001B[0mtriple_exists\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 243\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__add_triple_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtriple\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtriple_exists\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mquoted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    244\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    245\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtriple_exists\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Education/Formal_languages/formal-lang-course/venv/lib/python3.9/site-packages/rdflib/plugins/stores/memory.py\u001B[0m in \u001B[0;36m__add_triple_context\u001B[0;34m(self, triple, triple_exists, context, quoted)\u001B[0m\n\u001B[1;32m    488\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    489\u001B[0m         \u001B[0;31m# if this is the first ever triple in the store, set default ctx info\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 490\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__defaultContexts\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    491\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__defaultContexts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtriple_context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    492\u001B[0m         \u001B[0;31m# if the context info is the same as default, no need to store it\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Объекты использующихся графов\n",
    "\n",
    "from project.graph_tools import get_from_dataset\n",
    "\n",
    "GRAPHS = []\n",
    "\n",
    "for graph_name in GRAPH_NAMES:\n",
    "  GRAPHS.append(get_from_dataset(graph_name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "SdpC3YPgFusz",
    "outputId": "f14b21d7-a15f-4b3a-af62-7e3f9568a68e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Информация об использующихся графах\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "node_numbers = []\n",
    "edge_numbers = []\n",
    "for graph in GRAPHS:\n",
    "  node_number, edge_number = graph.description.nodes, graph.description.edges\n",
    "  node_numbers.append(node_number)\n",
    "  edge_numbers.append(edge_number)\n",
    "\n",
    "graph_descriptions_df = pd.DataFrame(\n",
    "    {\n",
    "      \"Node number\": node_numbers,\n",
    "      \"Edge number\": edge_numbers\n",
    "    },\n",
    "    index=GRAPH_NAMES\n",
    ")\n",
    "\n",
    "graph_descriptions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpSNNIRicWs6"
   },
   "source": [
    "### Запросы\n",
    "\n",
    "Запросы представляют из себя регулярные выражения. В них используются все общепринятые конструкции регулярных выражений (замыкание, конкатенация, альтернатива).\n",
    "\n",
    "Ниже приведён набор из четырёх используемых запросов.\n",
    "- $(L_0 | L_1)^* L_2$\n",
    "- $L_0 | L_2 | L_1^*$\n",
    "- $L_0 L_1 L_2 (L_3 | L_1)^*$\n",
    "- $(L_0 | L_3)^* | (L_1 | L_2)^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxC_RopAi2fg"
   },
   "source": [
    "#### Генераторы запросов\n",
    "\n",
    "\n",
    "Функции ниже отвечают за генерацию запросов как регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZZa4rOarGL8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Создание генераторов регулярных выражений --- запросов к графам\n",
    "\n",
    "from pyformlang.regular_expression.regex_objects import Symbol\n",
    "\n",
    "def _regex_from_label(label):\n",
    "  regex = Regex(\"\")\n",
    "  regex.head = Symbol(str(label))\n",
    "\n",
    "  return regex\n",
    "\n",
    "# (L0 | L1)* L2\n",
    "def query_one(labels):\n",
    "  \"\"\"\n",
    "  (L0 | L1)* L2\n",
    "  \"\"\"\n",
    "\n",
    "  label_regex_0 = _regex_from_label(labels[0])\n",
    "  label_regex_1 = _regex_from_label(labels[1])\n",
    "  label_regex_2 = _regex_from_label(labels[2])\n",
    "\n",
    "  return label_regex_0.union(label_regex_1).kleene_star().concatenate(label_regex_2)\n",
    "\n",
    "# L0 | L2 | L1*\n",
    "def query_two(labels):\n",
    "  \"\"\"\n",
    "  L0 | L2 | L1*\n",
    "  \"\"\"\n",
    "\n",
    "  label_regex_0 = _regex_from_label(labels[0])\n",
    "  label_regex_1 = _regex_from_label(labels[1])\n",
    "  label_regex_2 = _regex_from_label(labels[2])\n",
    "\n",
    "  return label_regex_0.union(label_regex_2).union(label_regex_1.kleene_star())\n",
    "\n",
    "# L0 L1 L2 (L3 | L1)*\n",
    "def query_three(labels):\n",
    "  \"\"\"\n",
    "  L0 L1 L2 (L3 | L1)*\n",
    "  \"\"\" \n",
    "\n",
    "  label_regex_0 = _regex_from_label(labels[0])\n",
    "  label_regex_1 = _regex_from_label(labels[1])\n",
    "  label_regex_2 = _regex_from_label(labels[2])\n",
    "  label_regex_3 = _regex_from_label(labels[3])\n",
    "\n",
    "  return label_regex_0.concatenate(label_regex_1).concatenate(label_regex_2).\\\n",
    "  concatenate((label_regex_3.union(label_regex_1)).kleene_star())\n",
    "\n",
    "# (L0 | L3)* | (L1 | L2)*\n",
    "def query_four(labels):\n",
    "  \"\"\"\n",
    "  (L0 | L3)* | (L1 | L2)*\n",
    "  \"\"\"\n",
    "\n",
    "  label_regex_0 = _regex_from_label(labels[0])\n",
    "  label_regex_1 = _regex_from_label(labels[1])\n",
    "  label_regex_2 = _regex_from_label(labels[2])\n",
    "  label_regex_3 = _regex_from_label(labels[3])\n",
    "\n",
    "  left_regex_part = (label_regex_0.union(label_regex_3)).kleene_star()\n",
    "  right_regex_part = (label_regex_1.union(label_regex_2)).kleene_star()\n",
    "\n",
    "  return left_regex_part.union(right_regex_part)\n",
    "\n",
    "QUERIES = [query_one, query_two, query_three, query_four]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63VKNyv6pe9D"
   },
   "source": [
    "---\n",
    "\n",
    "## Исследуемые версии алгоритма\n",
    "\n",
    "Элементами матрицы смежности для конечного автомата являются подмножества его меток, по которым возможен переход в данных состояниях. Чтобы не вводить операцию пересечения множеств в тензорном произведении, матрицы смежности двух конечных автоматов приводятся к виду булевых матриц по подмножеству символов.\n",
    "\n",
    "На практике, булевы матрицы являются сильно разреженными. Поэтому сравниваемые версии алгоритма используют библиотеки для работы с разреженными матрицами:\n",
    "\n",
    "- [scipy.sparse](https://docs.scipy.org/doc/scipy/reference/sparse.html): библиотека, использующаяся для реализаций операций с разряженными булевыми $dok$ матрицами на $CPU$;\n",
    "- [pyCuBool](https://pypi.org/project/pycubool/): библиотека, использующаяся для реализаций операций с разряженными булевыми матрицами на $GPU$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb7j1dm2-8xH"
   },
   "source": [
    "### Реализация СPU-версии алгоритма ($scipy.sparse$) и GPU-версии алгоритма ($pyCuBool$)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKiGdZxi1X05",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Set, Dict, Union\n",
    "\n",
    "import pycubool as cb\n",
    "import scipy.sparse as sps\n",
    "from pyformlang.finite_automaton import NondeterministicFiniteAutomaton, Symbol, State\n",
    "\n",
    "\n",
    "class BooleanAdjacencies:\n",
    "    \"\"\"\n",
    "    Construct a Nondeterministic Finite Automaton boolean adjacency matrices\n",
    "    by symbols and encapsulates all the information lost in this case.\n",
    "\n",
    "    Supports CPU and GPU computing platforms.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    mode: str, default = \"cpu\"\n",
    "        Selected platform used for all calculations\n",
    "    boolean_adjacencies: Dict[Symbol, Union[sps.dok_matrix, cb.Matrix]]\n",
    "        Nondeterministic Finite Automaton boolean adjacency matrices by symbols\n",
    "    states_num: int\n",
    "        Number of states in specified Nondeterministic Finite Automaton\n",
    "    shape: Tuple[int, int]\n",
    "        Adjacency matrix size\n",
    "    states_nums: Dict[State, int]\n",
    "        States in specified Nondeterministic Finite Automaton and it's numbers\n",
    "    nums_states: Dict[int, State]\n",
    "        Numbers of states in specified Nondeterministic Finite Automaton\n",
    "        and the states itself\n",
    "    start_states: Set[State]\n",
    "        Start states in specified Nondeterministic Finite Automaton\n",
    "    final_states: Set[State]\n",
    "        Final states in specified Nondeterministic Finite Automaton\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, nfa: NondeterministicFiniteAutomaton = None, mode: str = \"cpu\"\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        BooleanAdjacencies class constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nfa: NondeterministicFiniteAutomaton, default = None\n",
    "            Nondeterministic Finite Automaton to construct boolean adjacency matrices\n",
    "        mode: str, default = \"cpu\"\n",
    "            Allows to select the platform used for all calculations\n",
    "        \"\"\"\n",
    "\n",
    "        modes = [\"cpu\", \"gpu\"]\n",
    "        if mode not in modes:\n",
    "            raise ValueError(\"Invalid computing platform specified\")\n",
    "        self.mode = mode\n",
    "\n",
    "        self.states_num = 0\n",
    "        self.shape = (self.states_num, self.states_num)\n",
    "        self.states_nums = dict()\n",
    "        self.nums_states = dict()\n",
    "        self.start_states = set()\n",
    "        self.final_states = set()\n",
    "\n",
    "        self.boolean_adjacencies = dict()\n",
    "\n",
    "        if nfa is not None:\n",
    "            self.states_num = len(nfa.states)\n",
    "            self.shape = (self.states_num, self.states_num)\n",
    "            self.states_nums = {state: num for num, state in enumerate(nfa.states)}\n",
    "            self.nums_states = {num: state for num, state in enumerate(nfa.states)}\n",
    "            self.start_states = nfa.start_states\n",
    "            self.final_states = nfa.final_states\n",
    "\n",
    "            transition_func = nfa.to_dict()\n",
    "            self.boolean_adjacencies = self._get_boolean_adjacencies(transition_func)\n",
    "\n",
    "    def _get_boolean_adjacencies(\n",
    "        self, transition_func: Dict[State, Dict[Symbol, Union[State, Set[State]]]]\n",
    "    ) -> Dict[Symbol, Union[sps.dok_matrix, cb.Matrix]]:\n",
    "        \"\"\"\n",
    "        Construct a Nondeterministic Finite Automaton boolean adjacency\n",
    "        matrices by symbols.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_func: Dict[State, Dict[Symbol, Union[State, Set[State]]]]\n",
    "            Transition function of Nondeterministic Finite Automaton\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[Symbol, Union[sps.dok_matrix, cb.Matrix]]\n",
    "            Nondeterministic Finite Automaton boolean adjacency matrices\n",
    "            by symbols\n",
    "        \"\"\"\n",
    "\n",
    "        boolean_adjacencies = dict()\n",
    "\n",
    "        for state_from, transitions in transition_func.items():\n",
    "            for symbol, states_to in transitions.items():\n",
    "                if not isinstance(states_to, set):\n",
    "                    states_to = {states_to}\n",
    "\n",
    "                for state_to in states_to:\n",
    "                    state_from_num = self.states_nums[state_from]\n",
    "                    state_to_num = self.states_nums[state_to]\n",
    "\n",
    "                    if self.mode == \"cpu\":\n",
    "                        if symbol not in boolean_adjacencies:\n",
    "                            boolean_adjacencies[\n",
    "                                symbol\n",
    "                            ]: sps.dok_matrix = sps.dok_matrix(self.shape, dtype=bool)\n",
    "\n",
    "                        boolean_adjacencies[symbol][state_from_num, state_to_num] = True\n",
    "\n",
    "                    if self.mode == \"gpu\":\n",
    "                        if symbol not in boolean_adjacencies:\n",
    "                            boolean_adjacencies[symbol]: cb.Matrix = cb.Matrix.empty(\n",
    "                                self.shape\n",
    "                            )\n",
    "\n",
    "                        boolean_adjacencies[symbol][state_from_num, state_to_num] = True\n",
    "\n",
    "        return boolean_adjacencies\n",
    "\n",
    "    def intersect(self, other):\n",
    "        \"\"\"\n",
    "        Makes the intersection of two Nondeterministic Finite Automaton\n",
    "        presented as boolean adjacency matrices by symbols.\n",
    "\n",
    "        Warnings\n",
    "        --------\n",
    "        This method is NOT commutative:\n",
    "        other should be QUERY Nondeterministic Finite Automaton\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        other: BooleanAdjacencies\n",
    "            BooleanAdjacencies of Nondeterministic Finite Automaton\n",
    "            to intersect with\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        BooleanAdjacencies\n",
    "            The result of intersection presented as\n",
    "            boolean adjacency matrices by symbols\n",
    "        \"\"\"\n",
    "\n",
    "        intersection = BooleanAdjacencies()\n",
    "        intersection.mode = self.mode\n",
    "\n",
    "        intersection.states_num = self.states_num * other.states_num\n",
    "        intersection.shape = (intersection.states_num, intersection.states_num)\n",
    "        intersection_symbols = (\n",
    "            self.boolean_adjacencies.keys() & other.boolean_adjacencies.keys()\n",
    "        )\n",
    "\n",
    "        for symbol in intersection_symbols:\n",
    "            if self.mode == \"cpu\":\n",
    "                intersection.boolean_adjacencies[symbol] = sps.kron(\n",
    "                    self.boolean_adjacencies[symbol],\n",
    "                    other.boolean_adjacencies[symbol],\n",
    "                    format=\"dok\",\n",
    "                )\n",
    "\n",
    "            if self.mode == \"gpu\":\n",
    "                self_boolean_adjacency_indices = self.boolean_adjacencies[\n",
    "                    symbol\n",
    "                ].to_lists()\n",
    "                other_boolean_adjacency_indices = other.boolean_adjacencies[\n",
    "                    symbol\n",
    "                ].to_lists()\n",
    "                intersection.boolean_adjacencies[symbol] = cb.Matrix.from_lists(\n",
    "                    shape=self.shape,\n",
    "                    rows=self_boolean_adjacency_indices[0],\n",
    "                    cols=self_boolean_adjacency_indices[1],\n",
    "                ).kronecker(\n",
    "                    cb.Matrix.from_lists(\n",
    "                        shape=other.shape,\n",
    "                        rows=other_boolean_adjacency_indices[0],\n",
    "                        cols=other_boolean_adjacency_indices[1],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        for graph_state, graph_state_num in self.states_nums.items():\n",
    "            for query_state, query_state_num in other.states_nums.items():\n",
    "                intersection_state = State(str(query_state) + \"⋂\" + str(graph_state))\n",
    "                intersection_state_num = (\n",
    "                    graph_state_num * other.states_num + query_state_num\n",
    "                )\n",
    "\n",
    "                intersection.states_nums[intersection_state] = intersection_state_num\n",
    "                intersection.nums_states[intersection_state_num] = intersection_state\n",
    "\n",
    "                if (\n",
    "                    graph_state in self.start_states\n",
    "                    and query_state in other.start_states\n",
    "                ):\n",
    "                    intersection.start_states.add(intersection_state)\n",
    "\n",
    "                if (\n",
    "                    graph_state in self.final_states\n",
    "                    and query_state in other.final_states\n",
    "                ):\n",
    "                    intersection.final_states.add(intersection_state)\n",
    "\n",
    "        return intersection\n",
    "\n",
    "    def get_transitive_closure(self) -> Union[sps.dok_matrix, cb.Matrix]:\n",
    "        \"\"\"\n",
    "        Makes the transitive closure of Nondeterministic Finite Automaton\n",
    "        presented as boolean adjacency matrices by symbols.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Union[sps.dok_matrix, cb.Matrix]:\n",
    "            Nondeterministic Finite Automaton transitive closure\n",
    "        \"\"\"\n",
    "\n",
    "        if self.mode == \"cpu\":\n",
    "            transitive_closure: sps.dok_matrix = sps.dok_matrix(\n",
    "                sps.csr_matrix(\n",
    "                    sum(\n",
    "                        boolean_adjacency\n",
    "                        for boolean_adjacency in self.boolean_adjacencies.values()\n",
    "                    ),\n",
    "                    dtype=bool,\n",
    "                ),\n",
    "                dtype=bool,\n",
    "            )\n",
    "\n",
    "            current_nonzeros = transitive_closure.nnz\n",
    "            next_nonzeros = 0\n",
    "\n",
    "            while current_nonzeros != next_nonzeros:\n",
    "                transitive_closure += transitive_closure @ transitive_closure\n",
    "\n",
    "                current_nonzeros, next_nonzeros = next_nonzeros, transitive_closure.nnz\n",
    "\n",
    "            return transitive_closure\n",
    "\n",
    "        if self.mode == \"gpu\":\n",
    "            shape = (0, 0)\n",
    "            if self.shape == shape:\n",
    "                shape = (1, 1)\n",
    "            else:\n",
    "                shape = self.shape\n",
    "            transitive_closure: cb.Matrix = cb.Matrix.empty(shape)\n",
    "\n",
    "            for boolean_adjacency in self.boolean_adjacencies.values():\n",
    "                boolean_adjacency_indices = boolean_adjacency.to_lists()\n",
    "\n",
    "                transitive_closure = transitive_closure.ewiseadd(\n",
    "                    cb.Matrix.from_lists(\n",
    "                        shape=shape,\n",
    "                        rows=boolean_adjacency_indices[0],\n",
    "                        cols=boolean_adjacency_indices[1],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            current_nonzeros = len(transitive_closure.to_list())\n",
    "            next_nonzeros = 0\n",
    "\n",
    "            while current_nonzeros != next_nonzeros:\n",
    "                transitive_closure_pow: cb.Matrix = transitive_closure.mxm(\n",
    "                    transitive_closure\n",
    "                )\n",
    "                transitive_closure = transitive_closure.ewiseadd(transitive_closure_pow)\n",
    "\n",
    "                current_nonzeros, next_nonzeros = next_nonzeros, len(\n",
    "                    transitive_closure.to_list()\n",
    "                )\n",
    "\n",
    "            return transitive_closure\n",
    "\n",
    "    def to_nfa(self) -> NondeterministicFiniteAutomaton:\n",
    "        \"\"\"\n",
    "        Construct a Nondeterministic Finite Automaton from\n",
    "        it's boolean adjacency matrices by symbols.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        NondeterministicFiniteAutomaton\n",
    "            The resulting Nondeterministic Finite Automaton\n",
    "        \"\"\"\n",
    "\n",
    "        nfa = NondeterministicFiniteAutomaton()\n",
    "\n",
    "        for symbol, boolean_adjacency in self.boolean_adjacencies.items():\n",
    "            if self.mode == \"cpu\":\n",
    "                boolean_adjacency_indices = sps.dok_matrix(\n",
    "                    boolean_adjacency, dtype=bool\n",
    "                ).nonzero()\n",
    "\n",
    "                for state_from_num, state_to_num in zip(*boolean_adjacency_indices):\n",
    "                    state_from = self.nums_states[state_from_num]\n",
    "                    state_to = self.nums_states[state_to_num]\n",
    "\n",
    "                    nfa.add_transition(state_from, symbol, state_to)\n",
    "\n",
    "            if self.mode == \"gpu\":\n",
    "                boolean_adjacency_indices = boolean_adjacency.to_lists()\n",
    "\n",
    "                for state_from_num, state_to_num in zip(*boolean_adjacency_indices):\n",
    "                    state_from = self.nums_states[state_from_num]\n",
    "                    state_to = self.nums_states[state_to_num]\n",
    "\n",
    "                    nfa.add_transition(state_from, symbol, state_to)\n",
    "\n",
    "        for start_state in self.start_states:\n",
    "            nfa.add_start_state(start_state)\n",
    "\n",
    "        for final_state in self.final_states:\n",
    "            nfa.add_final_state(final_state)\n",
    "\n",
    "        return nfa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfmV5OHrlX4M"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FC6XV1dclP5G"
   },
   "source": [
    "### Реализация общего алгоритма $RPQ$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElRYJ5AM1wHb",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import networkx as nx\n",
    "from pyformlang.regular_expression import Regex\n",
    "\n",
    "from project.automaton_tools import get_min_dfa_from_regex, get_nfa_from_graph\n",
    "\n",
    "\n",
    "def regular_str_path_querying(\n",
    "    graph: nx.MultiDiGraph,\n",
    "    query_str: str,\n",
    "    result: Tuple[Set],\n",
    "    start_node_nums: Set[int] = None,\n",
    "    final_node_nums: Set[int] = None,\n",
    "    mode: str = \"cpu\",\n",
    ") -> Set[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Using the specified graph and a regular query,\n",
    "    finds all pairs of reachable node numbers.\n",
    "\n",
    "    If actual regex is specified, regex_str is no longer taken into account.\n",
    "\n",
    "    If start_nodes or final_nodes are not specified,\n",
    "    all nodes are considered start or final respectively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph: nx.MultiDiGraph\n",
    "        Graph for queries\n",
    "    query_str: str\n",
    "        Query to graph as a string\n",
    "    start_node_nums: Set[int], default = None\n",
    "        Set of start node numbers to configure Nondeterministic Finite Automaton,\n",
    "        which must exist in the graph\n",
    "    final_node_nums: Set[int], default = None\n",
    "        Set of final node numbers to configure Nondeterministic Finite Automaton,\n",
    "        which must exist in the graph\n",
    "    mode: str, default = \"cpu\"\n",
    "        Allows to select the platform used for all calculations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Set[Tuple[int, int]]\n",
    "        Set of all pairs of reachable node numbers\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If invalid computing platform specified\n",
    "    ValueError\n",
    "        If non-existent in the specified graph node number is used\n",
    "    MisformedRegexError\n",
    "        If specified regex_str has an irregular format\n",
    "    \"\"\"\n",
    "\n",
    "    result = regular_path_querying(\n",
    "        graph, Regex(query_str), start_node_nums, final_node_nums, mode\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def regular_path_querying(\n",
    "    graph: nx.MultiDiGraph,\n",
    "    query_regex: Regex,\n",
    "    result: Tuple[Set],\n",
    "    start_node_nums: Set[int] = None,\n",
    "    final_node_nums: Set[int] = None,\n",
    "    mode: str = \"cpu\",\n",
    ") -> Set[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Using the specified graph and a regular query,\n",
    "    finds all pairs of reachable node numbers.\n",
    "\n",
    "    If start_nodes or final_nodes are not specified,\n",
    "    all nodes are considered start or final respectively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph: nx.MultiDiGraph\n",
    "        Graph for queries\n",
    "    query_regex: Regex\n",
    "        Query to graph as complete Regex\n",
    "    start_node_nums: Set[int], default = None\n",
    "        Set of start node numbers to configure Nondeterministic Finite Automaton,\n",
    "        which must exist in the graph\n",
    "    final_node_nums: Set[int], default = None\n",
    "        Set of final node numbers to configure Nondeterministic Finite Automaton,\n",
    "        which must exist in the graph\n",
    "    mode: str, default = \"cpu\"\n",
    "        Allows to select the platform used for all calculations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Set[Tuple[int, int]]\n",
    "        Set of all pairs of reachable node numbers\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If invalid computing platform specified\n",
    "    ValueError\n",
    "        If non-existent in the specified graph node number is used\n",
    "    MisformedRegexError\n",
    "        If specified regex_str has an irregular format\n",
    "    \"\"\"\n",
    "\n",
    "    graph = BooleanAdjacencies(\n",
    "        get_nfa_from_graph(graph, start_node_nums, final_node_nums), mode\n",
    "    )\n",
    "\n",
    "    query = BooleanAdjacencies(get_min_dfa_from_regex(query_regex), mode)\n",
    "\n",
    "    intersection = graph.intersect(query)\n",
    "    transitive_closure = intersection.get_transitive_closure()\n",
    "\n",
    "    reachable_state_nums = set()\n",
    "\n",
    "    if mode == \"cpu\":\n",
    "        for state_from_num, state_to_num in zip(*transitive_closure.nonzero()):\n",
    "            state_from = intersection.nums_states[state_from_num]\n",
    "            state_to = intersection.nums_states[state_to_num]\n",
    "\n",
    "            if (\n",
    "                state_from in intersection.start_states\n",
    "                and state_to in intersection.final_states\n",
    "            ):\n",
    "                reachable_state_from_num = state_from_num // query.states_num\n",
    "                reachable_state_to_num = state_to_num // query.states_num\n",
    "\n",
    "                reachable_state_nums.add(\n",
    "                    (reachable_state_from_num, reachable_state_to_num)\n",
    "                )\n",
    "\n",
    "    if mode == \"gpu\":\n",
    "        for state_from_num, state_to_num in zip(*transitive_closure.to_lists()):\n",
    "            state_from = intersection.nums_states[state_from_num]\n",
    "            state_to = intersection.nums_states[state_to_num]\n",
    "\n",
    "            if (\n",
    "                state_from in intersection.start_states\n",
    "                and state_to in intersection.final_states\n",
    "            ):\n",
    "                reachable_state_from_num = state_from_num // query.states_num\n",
    "                reachable_state_to_num = state_to_num // query.states_num\n",
    "\n",
    "                reachable_state_nums.add(\n",
    "                    (reachable_state_from_num, reachable_state_to_num)\n",
    "                )\n",
    "\n",
    "\n",
    "    result = reachable_state_nums\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uw0B5LpxClK"
   },
   "source": [
    "---\n",
    "\n",
    "## Сравнение производительности версий алгоритма\n",
    "\n",
    "Для сравнения времени работы (в **мс.**) версий $CPU$- и $GPU$-версий алгоритма к каждому графу задается по 4 запроса, каждый из которых выполняется 3 раза для поддержания баланса между точностью результата и длительностью эксперимента. При меньшей выборке теряется точность результата, при большей - длительность посчёта выходит за рамки разумного. В качестве результата берётся наилучшее (наименьшее) время.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebgoskPJnbMH"
   },
   "source": [
    "### Платформа для исследования\n",
    "\n",
    "Ниже представлена доступная информация о платформе **Google Colab**, на которой проходили эксперименты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPcZMZ_ZMHUC"
   },
   "source": [
    "#### ОС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyNw0qDFMMOT",
    "outputId": "319dd3f2-2dbd-4315-f14c-ccdcfce3b4db",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skUL4m3PMOZA"
   },
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVh8K7y1MUNC",
    "outputId": "f3507900-0dea-4799-c2c2-416e01b44687",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!lscpu | grep 'Model name'\n",
    "!lscpu | grep 'Socket(s)'\n",
    "!lscpu | grep 'Core(s) per socket:'\n",
    "!lscpu | grep 'Thread(s) per core'\n",
    "!lscpu | grep \"MHz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYsspo-8MVv8"
   },
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8jkr6A9DMX-8",
    "outputId": "cfbe540d-1309-4fff-a62b-8ca4a1ece67a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wh-3iK4XMZV4"
   },
   "source": [
    "#### RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaCDHn8yMb3B",
    "outputId": "af249fc5-f2c5-43cc-91bd-4ab0dbefeb96",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!grep MemTotal /proc/meminfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ej4wol4pthh"
   },
   "source": [
    "### Производительность СPU-версии алгоритма ($scipy.sparse$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juk8SmezGcz6",
    "outputId": "2dfb9ad1-4775-43c2-e822-c9382bbb92e9",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== VERSION BASED ON CPU (scipy.sparse) ===\")\n",
    "\n",
    "queries = [\"(L0 | L1)* L2\", \"L0 | L2 | L1*\",\n",
    "          \"L0 L1 L2 (L3 | L1)*\", \"(L0 | L3)* | (L1 | L2)*\"]\n",
    "\n",
    "cpu_times_df = pd.DataFrame(index=queries, columns=GRAPH_NAMES)\n",
    "cpu_results = dict((graph.description.name, []) for graph in GRAPHS)\n",
    "\n",
    "for graph in GRAPHS:\n",
    "  labels = list(graph.description.edge_labels)\n",
    "\n",
    "  for index, query_generator in enumerate(QUERIES):\n",
    "    query = query_generator(labels)\n",
    "\n",
    "    print(str(graph))\n",
    "    print(f\"Query: {query_generator.__doc__}\")\n",
    "    print(\"Perfomance:\")\n",
    "    results = tuple()\n",
    "    time = None\n",
    "    if graph.description.name not in [\"go_hierarchy\", \"eclass_514en\", \"geospecies\"]:\n",
    "      time = %timeit -n 3 -o regular_path_querying(graph.graph, query, results, mode=\"cpu\")\n",
    "    else:\n",
    "      time = %timeit -n 1 -o regular_path_querying(graph.graph, query, results, mode=\"cpu\")\n",
    "    print(\"=== === ===\")\n",
    "\n",
    "    cpu_times_df.loc[queries[index], graph.description.name] = round(time.best * 1000, 2)\n",
    "    cpu_results[graph.description.name].append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLxI1S49Ygb0"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgDG3ljCLwIZ"
   },
   "source": [
    "В таблице ниже показано время работы данной версии алгоритма (в **мс**.) в зависимости от графа и регулярного выражения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "Qfh7p5AQTD3j",
    "outputId": "2202d40c-5e19-4608-9bae-eae4e7a60ea7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cpu_times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il_VJLPxqDSs"
   },
   "source": [
    "### Производительность GPU-версии алгоритма ($pyCuBool$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eey92j1aIjam",
    "outputId": "4aceb818-30ce-487d-8dcc-c68ae997dd1d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== VERSION BASED ON GPU (pyCuBool) ===\")\n",
    "\n",
    "gpu_times_df = pd.DataFrame(index=queries, columns=GRAPH_NAMES)\n",
    "gpu_results = dict((graph.description.name, []) for graph in GRAPHS)\n",
    "\n",
    "for graph in GRAPHS:\n",
    "  labels = list(graph.description.edge_labels)\n",
    "\n",
    "  for index, query_generator in enumerate(QUERIES):\n",
    "    query = query_generator(labels)\n",
    "\n",
    "    print(str(graph))\n",
    "    print(f\"Query: {query_generator.__doc__}\")\n",
    "    print(\"Perfomance:\")\n",
    "    results = tuple()\n",
    "    time = None\n",
    "    if graph.description.name not in [\"go_hierarchy\", \"eclass_514en\", \"geospecies\"]:\n",
    "      time = %timeit -n 3 -o regular_path_querying(graph.graph, query, results, mode=\"gpu\")\n",
    "    else:\n",
    "      time = %timeit -n 1 -o regular_path_querying(graph.graph, query, results, mode=\"gpu\")\n",
    "    print(\"=== === ===\")\n",
    "\n",
    "    gpu_times_df.loc[queries[index], graph.description.name] = round(time.best * 1000, 2)\n",
    "    gpu_results[graph.description.name].append(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkFUVev-O7c9"
   },
   "source": [
    "В таблице ниже показано время работы данной версии алгоритма (в **мс**.) в зависимости от графа и регулярного выражения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "id": "FJ3fSKKS7hYu",
    "outputId": "cea184fc-ef00-4542-e927-4e6259dddd29",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "gpu_times_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piuMPLylY73D"
   },
   "source": [
    "### Зависимость производительности от параметров графа\n",
    "\n",
    "Для запроса $L_0 L_1 L_2 (L_3 | L_1)^*$ построены графики зависимости времени решения проблемы $RPQ$ от количества вершин и ребёр графа на примере **GPU-версии алгоритма ($pyCuBool$)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRbijxh-sGvg"
   },
   "source": [
    "#### От количества вершин\n",
    "\n",
    "Рассмотрим зависимость производительности от количества вершин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "El5Fwe1NWIL6",
    "outputId": "7e62f98b-d170-4b99-b7e2-c2ff35b2a9ba",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Лучшее время выполнения GPU-версии алгоритма RPQ (pyCuBool)\n",
    "# на запросе L0 L1 L2 (L3 | L1)*\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [graph.description.nodes for graph in GRAPHS]\n",
    "Y = [gpu_times_df[graph.description.name][2] for graph in GRAPHS]\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.plot(X, Y)\n",
    "plt.xlabel(\"Вершины\")\n",
    "plt.ylabel(\"Время выполнения (мс.)\")\n",
    "plt.title(\"Зависимость времени работы версии алгоритма от количества вершин в графе\")\n",
    "\n",
    "for x, y, name in zip(X, Y, GRAPH_NAMES):\n",
    "  plt.annotate(name, (x, y), textcoords=\"offset points\", xytext=(-20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtTOwgo1mvAM"
   },
   "source": [
    "По графику наблюдается наличие зависимости времени выполнения алгоритма от числа вершин графа. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXwVW74csSDY"
   },
   "source": [
    "#### От количества ребер\n",
    "\n",
    "Рассмотрим зависимость производительности от количества рёбер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dYkI_4MjnAPz",
    "outputId": "1414f02e-7323-4252-d8ce-ae8973f055ca",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Лучшее время выполнения GPU-версии алгоритма RPQ (pyCuBool)\n",
    "# на запросе L0 L1 L2 (L3 | L1)*\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [graph.description.edges for graph in GRAPHS]\n",
    "Y = [gpu_times_df[graph.description.name][2] for graph in GRAPHS]\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.plot(X, Y)\n",
    "plt.xlabel(\"Ребра\")\n",
    "plt.ylabel(\"Время выполнения (мс.)\")\n",
    "plt.title(\"Зависимость времени работы версии алгоритма от количества ребер в графе\")\n",
    "\n",
    "for x, y, name in zip(X, Y, GRAPH_NAMES):\n",
    "  plt.annotate(name, (x, y), textcoords=\"offset points\", xytext=(-20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7egEFs1wTXs"
   },
   "source": [
    "Наблюдается ещё более выраженная зависимость времени выполнения от количества рёбер в графе, чем от количества вершин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYSZ3lyEwW3l"
   },
   "source": [
    "## Итоги исследования\n",
    "\n",
    "Алгоритм решения проблемы $RPQ$ показал лучшие результаты в случае использования реализации с применением $pyCuBool$ для выполнения операций с булевыми матрицами. Данный результат объясняется тем, что библиотека $pyCuBool$ в своей реализации применяет технологию $NVIDIA$ $CUDA$, использующую графический ускоритель для вычислений. По данным эксперимента можно судить об эффективности параллельных вычислений при помощи данной технологии."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "RPQ research",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}